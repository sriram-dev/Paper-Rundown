{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model \n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, Activation, MaxPooling2D, Input, Lambda\n",
    "from keras import backend as k \n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from PIL import Image\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Helper method triplet sampler taken from https://github.com/akarshzingade/image-similarity-deep-ranking . This will help create a textfile with path to anchor, positive and negative images from the given input directory classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tripletsampler import triplet_sampler\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "triplet_sampler(\"data/train\", \".\", 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a file \"triplets.txt\" in the same folder as notebook file. Now lets use pandas to read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11425, 3)\n",
      "(11425, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train\\tulip\\142218310_d06005030a_n.jpg</td>\n",
       "      <td>data/train\\tulip\\11746452_5bc1749a36.jpg</td>\n",
       "      <td>data/train\\dandelion\\138132145_782763b84f_m.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train\\daisy\\172882635_4cc7b86731_m.jpg</td>\n",
       "      <td>data/train\\daisy\\520752848_4b87fb91a4.jpg</td>\n",
       "      <td>data/train\\rose\\563847503_89e9756c80.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train\\daisy\\422094774_28acc69a8b_n.jpg</td>\n",
       "      <td>data/train\\daisy\\102841525_bd6628ae3c.jpg</td>\n",
       "      <td>data/train\\rose\\2788276815_8f730bd942.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train\\dandelion\\138166590_47c6cb9dd0.jpg</td>\n",
       "      <td>data/train\\dandelion\\921252114_91e334b950.jpg</td>\n",
       "      <td>data/train\\sunflower\\50987813_7484bfbcdf.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train\\sunflower\\40410963_3ac280f23a_n.jpg</td>\n",
       "      <td>data/train\\sunflower\\45045003_30bbd0a142_m.jpg</td>\n",
       "      <td>data/train\\dandelion\\344318990_7be3fb0a7d.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0  \\\n",
       "0     data/train\\tulip\\142218310_d06005030a_n.jpg   \n",
       "1     data/train\\daisy\\172882635_4cc7b86731_m.jpg   \n",
       "2     data/train\\daisy\\422094774_28acc69a8b_n.jpg   \n",
       "3   data/train\\dandelion\\138166590_47c6cb9dd0.jpg   \n",
       "4  data/train\\sunflower\\40410963_3ac280f23a_n.jpg   \n",
       "\n",
       "                                                1  \\\n",
       "0        data/train\\tulip\\11746452_5bc1749a36.jpg   \n",
       "1       data/train\\daisy\\520752848_4b87fb91a4.jpg   \n",
       "2       data/train\\daisy\\102841525_bd6628ae3c.jpg   \n",
       "3   data/train\\dandelion\\921252114_91e334b950.jpg   \n",
       "4  data/train\\sunflower\\45045003_30bbd0a142_m.jpg   \n",
       "\n",
       "                                                 2  \n",
       "0  data/train\\dandelion\\138132145_782763b84f_m.jpg  \n",
       "1         data/train\\rose\\563847503_89e9756c80.jpg  \n",
       "2        data/train\\rose\\2788276815_8f730bd942.jpg  \n",
       "3     data/train\\sunflower\\50987813_7484bfbcdf.jpg  \n",
       "4    data/train\\dandelion\\344318990_7be3fb0a7d.jpg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv('triplets.txt',header=None)\n",
    "df = df.sample(frac=1)\n",
    "print(df.shape)\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train\\tulip\\142218310_d06005030a_n.jpg</td>\n",
       "      <td>data/train\\tulip\\11746452_5bc1749a36.jpg</td>\n",
       "      <td>data/train\\dandelion\\138132145_782763b84f_m.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train\\daisy\\172882635_4cc7b86731_m.jpg</td>\n",
       "      <td>data/train\\daisy\\520752848_4b87fb91a4.jpg</td>\n",
       "      <td>data/train\\rose\\563847503_89e9756c80.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train\\daisy\\422094774_28acc69a8b_n.jpg</td>\n",
       "      <td>data/train\\daisy\\102841525_bd6628ae3c.jpg</td>\n",
       "      <td>data/train\\rose\\2788276815_8f730bd942.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train\\dandelion\\138166590_47c6cb9dd0.jpg</td>\n",
       "      <td>data/train\\dandelion\\921252114_91e334b950.jpg</td>\n",
       "      <td>data/train\\sunflower\\50987813_7484bfbcdf.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train\\sunflower\\40410963_3ac280f23a_n.jpg</td>\n",
       "      <td>data/train\\sunflower\\45045003_30bbd0a142_m.jpg</td>\n",
       "      <td>data/train\\dandelion\\344318990_7be3fb0a7d.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0  \\\n",
       "0     data/train\\tulip\\142218310_d06005030a_n.jpg   \n",
       "1     data/train\\daisy\\172882635_4cc7b86731_m.jpg   \n",
       "2     data/train\\daisy\\422094774_28acc69a8b_n.jpg   \n",
       "3   data/train\\dandelion\\138166590_47c6cb9dd0.jpg   \n",
       "4  data/train\\sunflower\\40410963_3ac280f23a_n.jpg   \n",
       "\n",
       "                                                1  \\\n",
       "0        data/train\\tulip\\11746452_5bc1749a36.jpg   \n",
       "1       data/train\\daisy\\520752848_4b87fb91a4.jpg   \n",
       "2       data/train\\daisy\\102841525_bd6628ae3c.jpg   \n",
       "3   data/train\\dandelion\\921252114_91e334b950.jpg   \n",
       "4  data/train\\sunflower\\45045003_30bbd0a142_m.jpg   \n",
       "\n",
       "                                                 2  \n",
       "0  data/train\\dandelion\\138132145_782763b84f_m.jpg  \n",
       "1         data/train\\rose\\563847503_89e9756c80.jpg  \n",
       "2        data/train\\rose\\2788276815_8f730bd942.jpg  \n",
       "3     data/train\\sunflower\\50987813_7484bfbcdf.jpg  \n",
       "4    data/train\\dandelion\\344318990_7be3fb0a7d.jpg  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain = df.head(10000)\n",
    "dftest = df.tail(1000)\n",
    "dftrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/train\\tulip\\391477275_7c2f50a1a7_m.jpg</td>\n",
       "      <td>data/train\\tulip\\112428919_f0c5ad7d9d_n.jpg</td>\n",
       "      <td>data/train\\dandelion\\8684108_a85764b22d_n.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/train\\daisy\\498159452_b71afd65ba.jpg</td>\n",
       "      <td>data/train\\daisy\\25360380_1a881a5648.jpg</td>\n",
       "      <td>data/train\\rose\\2960709681_e95940c0f0_n.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/train\\tulip\\251811158_75fa3034ff.jpg</td>\n",
       "      <td>data/train\\tulip\\2229804138_db9cba3443_n.jpg</td>\n",
       "      <td>data/train\\rose\\2536282942_b5ca27577e.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data/train\\tulip\\112428919_f0c5ad7d9d_n.jpg</td>\n",
       "      <td>data/train\\tulip\\113291410_1bdc718ed8_n.jpg</td>\n",
       "      <td>data/train\\sunflower\\200288046_0032f322ff_n.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data/train\\rose\\272481307_1eb47ba3e0_n.jpg</td>\n",
       "      <td>data/train\\rose\\1392579828_ab5a139052.jpg</td>\n",
       "      <td>data/train\\sunflower\\244074259_47ce6d3ef9.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             0  \\\n",
       "0  data/train\\tulip\\391477275_7c2f50a1a7_m.jpg   \n",
       "1    data/train\\daisy\\498159452_b71afd65ba.jpg   \n",
       "2    data/train\\tulip\\251811158_75fa3034ff.jpg   \n",
       "3  data/train\\tulip\\112428919_f0c5ad7d9d_n.jpg   \n",
       "4   data/train\\rose\\272481307_1eb47ba3e0_n.jpg   \n",
       "\n",
       "                                              1  \\\n",
       "0   data/train\\tulip\\112428919_f0c5ad7d9d_n.jpg   \n",
       "1      data/train\\daisy\\25360380_1a881a5648.jpg   \n",
       "2  data/train\\tulip\\2229804138_db9cba3443_n.jpg   \n",
       "3   data/train\\tulip\\113291410_1bdc718ed8_n.jpg   \n",
       "4     data/train\\rose\\1392579828_ab5a139052.jpg   \n",
       "\n",
       "                                                 2  \n",
       "0    data/train\\dandelion\\8684108_a85764b22d_n.jpg  \n",
       "1      data/train\\rose\\2960709681_e95940c0f0_n.jpg  \n",
       "2        data/train\\rose\\2536282942_b5ca27577e.jpg  \n",
       "3  data/train\\sunflower\\200288046_0032f322ff_n.jpg  \n",
       "4    data/train\\sunflower\\244074259_47ce6d3ef9.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest = dftest.reset_index(drop=True)\n",
    "dftest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train\\tulip\\142218310_d06005030a_n.jpg\n",
      "data/train\\tulip\\11746452_5bc1749a36.jpg\n",
      "data/train\\dandelion\\138132145_782763b84f_m.jpg\n"
     ]
    }
   ],
   "source": [
    "row_iterator = dftrain.iterrows()\n",
    "i, row = next(row_iterator)\n",
    "print(row[0])\n",
    "print(row[1])\n",
    "print(row[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! We have our dataset of over 11K triplets to work with now !! \n",
    "\n",
    "Lets load an image from the dataframe, just in case to verify!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train\\tulip\\142218310_d06005030a_n.jpg\n",
      "data/train\\daisy\\172882635_4cc7b86731_m.jpg\n",
      "data/train\\daisy\\422094774_28acc69a8b_n.jpg\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJsAAACICAYAAADwI5m5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4z8BWHclaafAgygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "print(dftrain[0][0])\n",
    "print(dftrain[0][1])\n",
    "print(dftrain[0][2])\n",
    "image1 = mpimg.imread(dftrain[0][0]) \n",
    "image2 = mpimg.imread(dftrain[0][1])\n",
    "image3 = mpimg.imread(dftrain[0][2])\n",
    "fig=plt.figure(figsize=(2, 2))\n",
    "fig.add_subplot(2, 2,1)\n",
    "plt.imshow(image1)\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.imshow(image2)\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.imshow(image3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load VGGNet model pre trained with imagenet. All we care about are the encodings that are produced from it so that we can train the model further based on loss function. \n",
    "TripletLoss helper is also imported from a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 256, 256, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 256, 256, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 128, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 128, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 64, 64, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 32, 32, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32768)             131072    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 19,056,704\n",
      "Trainable params: 11,355,904\n",
      "Non-trainable params: 7,700,800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sdesikan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"la...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from triplet_loss import triplet_loss,img_to_encoding, identity_loss\n",
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (256, 256, 3))\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "# L2 normalization\n",
    "X = Lambda(lambda  x: k.l2_normalize(x,axis=1))(x)\n",
    "# make till conv4 layer as non trainable \n",
    "for i in range(0,14):\n",
    "    model.layers[i].trainable = False\n",
    "base_model = Model(input = model.input, output = X)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_to_encoding(df[0][0], base_model, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          19056704    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "                                                                 model_1[3][0]                    \n",
      "==================================================================================================\n",
      "Total params: 19,056,704\n",
      "Trainable params: 11,355,904\n",
      "Non-trainable params: 7,700,800\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#base_model.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "input_1 = Input((img_width,img_height,3))\n",
    "input_2 = Input((img_width,img_height,3))\n",
    "input_3 = Input((img_width,img_height,3))\n",
    "\n",
    "r1 = base_model(input_1)\n",
    "r2 = base_model(input_2)\n",
    "r3 = base_model(input_3)\n",
    "y_pred = [r1,r2,r3]\n",
    "y_true = (None, None, None)\n",
    "loss = Lambda(triplet_loss, output_shape=(1,))(y_pred)\n",
    "print(loss.shape)\n",
    "model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "model.summary()\n",
    "model.compile(optimizer = 'adam', loss=identity_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate():\n",
    "    row_iterator = dftrain.iterrows()\n",
    "    while True:        \n",
    "        list_a = []\n",
    "        list_b = []\n",
    "        list_c = []\n",
    "        for i in range(batch_size):\n",
    "            i, row = next(row_iterator);     \n",
    "            anchor_img = Image.open(row[0].replace(\"\\\\\",\"/\"))\n",
    "            anchor_img = anchor_img.resize((img_width,img_height))\n",
    "            anchor_img_array = np.asarray(anchor_img)\n",
    "            positive_img = Image.open(row[1].replace(\"\\\\\",\"/\"))\n",
    "            positive_img = positive_img.resize((img_width,img_height))\n",
    "            positive_img_array = np.asarray(positive_img)\n",
    "            negative_img = Image.open(row[2].replace(\"\\\\\",\"/\"))\n",
    "            negative_img = negative_img.resize((img_width,img_height))\n",
    "            negative_img_array = np.asarray(negative_img)\n",
    "            #x_train = np.array([anchor_img_array, positive_img_array, negative_img_array])\n",
    "            #anchor  = np.array([anchor_img_array])\n",
    "            #positive  = np.array([positive_img_array])\n",
    "            #negative = np.array([negative_img_array])                \n",
    "            list_a.append(anchor_img_array)\n",
    "            list_b.append(positive_img_array)\n",
    "            list_c.append(negative_img_array)\n",
    "            if i is 9000:\n",
    "                row_iterator.seek(0)\n",
    "        A = np.array(list_a, dtype='float32')\n",
    "        B = np.array(list_b, dtype='float32')\n",
    "        C = np.array(list_c, dtype='float32')\n",
    "        label = np.ones(batch_size)\n",
    "        yield [A,B, C], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTest():\n",
    "    testrow_iterator = dftest.iterrows()\n",
    "    while True:        \n",
    "        list_a = []\n",
    "        list_b = []\n",
    "        list_c = []\n",
    "        for i in range(batch_size):\n",
    "            if row_iterator.finished is True:\n",
    "                row_iterator.reset()\n",
    "            i, row = next(testrow_iterator);            \n",
    "            anchor_img = Image.open(row[0].replace(\"\\\\\",\"/\"))\n",
    "            anchor_img = anchor_img.resize((img_width,img_height))\n",
    "            anchor_img_array = np.asarray(anchor_img)\n",
    "            positive_img = Image.open(row[1].replace(\"\\\\\",\"/\"))\n",
    "            positive_img = positive_img.resize((img_width,img_height))\n",
    "            positive_img_array = np.asarray(positive_img)\n",
    "            negative_img = Image.open(row[2].replace(\"\\\\\",\"/\"))\n",
    "            negative_img = negative_img.resize((img_width,img_height))\n",
    "            negative_img_array = np.asarray(negative_img)\n",
    "            #x_train = np.array([anchor_img_array, positive_img_array, negative_img_array])\n",
    "            #anchor  = np.array([anchor_img_array])\n",
    "            #positive  = np.array([positive_img_array])\n",
    "            #negative = np.array([negative_img_array])                \n",
    "            list_a.append(anchor_img_array)\n",
    "            list_b.append(positive_img_array)\n",
    "            list_c.append(negative_img_array)\n",
    "            if i is 1000:\n",
    "                testrow_iterator.seek(0)\n",
    "        A = np.array(list_a, dtype='float32')\n",
    "        B = np.array(list_b, dtype='float32')\n",
    "        C = np.array(list_c, dtype='float32')\n",
    "        label = np.ones(batch_size)\n",
    "        yield [A,B, C], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6938684\n"
     ]
    }
   ],
   "source": [
    "train_generator = Generate()\n",
    "test_generator = GenerateTest()\n",
    "batch = next(train_generator)\n",
    "print(model.predict_on_batch(batch[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 1682s - loss: 1.2406 - val_loss: 0.9204\n",
      "Epoch 2/5\n",
      " - 1611s - loss: 0.8610 - val_loss: 1.1309\n",
      "Epoch 3/5\n",
      " - 1595s - loss: 0.8391 - val_loss: 1.7000\n",
      "Epoch 4/5\n",
      " - 1598s - loss: 1.6459 - val_loss: 1.6159\n",
      "Epoch 5/5\n",
      " - 1601s - loss: 1.6507 - val_loss: 1.5643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xdd978825f8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, \n",
    "                    validation_data=test_generator, \n",
    "                    epochs=50, \n",
    "                    verbose=1, \n",
    "                    workers=1,\n",
    "                    steps_per_epoch=1000, \n",
    "                    validation_steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Layer model_1 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[ 39.,  26.,  17.],\n        [ 39.,  26.,  17.],\n        [ 38.,  25.,  16.],\n        ...,\n        [231., 188., 172.],\n        [213., 175., 164.],\n        [174., 140., 138.]],\n\n       [[ 37.,  24.,  15.],\n        [ 37.,  24.,  15.],\n        [ 38.,  25.,  16.],\n        ...,\n        [232., 189., 173.],\n        [215., 177., 168.],\n        [177., 143., 141.]],\n\n       [[ 39.,  26.,  17.],\n        [ 39.,  26.,  17.],\n        [ 39.,  26.,  17.],\n        ...,\n        [232., 189., 173.],\n        [213., 175., 166.],\n        [176., 142., 140.]],\n\n       ...,\n\n       [[ 82.,  55.,  44.],\n        [ 91.,  63.,  51.],\n        [ 92.,  63.,  47.],\n        ...,\n        [ 16.,  15.,  11.],\n        [ 31.,  30.,  25.],\n        [ 34.,  34.,  26.]],\n\n       [[ 80.,  57.,  43.],\n        [ 97.,  71.,  58.],\n        [ 96.,  69.,  52.],\n        ...,\n        [ 32.,  31.,  26.],\n        [ 36.,  35.,  30.],\n        [ 36.,  36.,  26.]],\n\n       [[ 93.,  70.,  56.],\n        [ 91.,  65.,  52.],\n        [ 95.,  68.,  51.],\n        ...,\n        [ 27.,  27.,  19.],\n        [ 38.,  38.,  28.],\n        [ 45.,  45.,  35.]]], dtype=float32)]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\sdesikan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m                 \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdesikan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    473\u001b[0m         raise ValueError('Unexpectedly found an instance of type `' +\n\u001b[1;32m--> 474\u001b[1;33m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-87287646962a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(model.predict([batch[0][0][0]), batch[0][0][0], batch[0][0][0]]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mbase_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\sdesikan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m             \u001b[1;31m# with the input_spec set at build time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[1;31m# Handle mask propagation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\sdesikan\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    283\u001b[0m                                  \u001b[1;34m'Received type: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full input: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m                                  \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. All inputs to the layer '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m                                  'should be tensors.')\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer model_1 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[ 39.,  26.,  17.],\n        [ 39.,  26.,  17.],\n        [ 38.,  25.,  16.],\n        ...,\n        [231., 188., 172.],\n        [213., 175., 164.],\n        [174., 140., 138.]],\n\n       [[ 37.,  24.,  15.],\n        [ 37.,  24.,  15.],\n        [ 38.,  25.,  16.],\n        ...,\n        [232., 189., 173.],\n        [215., 177., 168.],\n        [177., 143., 141.]],\n\n       [[ 39.,  26.,  17.],\n        [ 39.,  26.,  17.],\n        [ 39.,  26.,  17.],\n        ...,\n        [232., 189., 173.],\n        [213., 175., 166.],\n        [176., 142., 140.]],\n\n       ...,\n\n       [[ 82.,  55.,  44.],\n        [ 91.,  63.,  51.],\n        [ 92.,  63.,  47.],\n        ...,\n        [ 16.,  15.,  11.],\n        [ 31.,  30.,  25.],\n        [ 34.,  34.,  26.]],\n\n       [[ 80.,  57.,  43.],\n        [ 97.,  71.,  58.],\n        [ 96.,  69.,  52.],\n        ...,\n        [ 32.,  31.,  26.],\n        [ 36.,  35.,  30.],\n        [ 36.,  36.,  26.]],\n\n       [[ 93.,  70.,  56.],\n        [ 91.,  65.,  52.],\n        [ 95.,  68.,  51.],\n        ...,\n        [ 27.,  27.,  19.],\n        [ 38.,  38.,  28.],\n        [ 45.,  45.,  35.]]], dtype=float32)]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "#extract the model alone so that we could encode images now :)\n",
    "#batch = next(train_generator)\n",
    "print(batch[0][0][0, :].shape)\n",
    "#print(model.predict([batch[0][0][0]), batch[0][0][0], batch[0][0][0]]))\n",
    "base_model(batch[0][0][0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "inputlist= []\n",
    "outputlist = []\n",
    "for index, row in df.iterrows():\n",
    "    anchor_img = Image.open(row[0])\n",
    "    anchor_img = anchor_img.resize((img_width,img_height))\n",
    "    anchor_img_array = np.asarray(anchor_img)\n",
    "    positive_img = Image.open(row[1])\n",
    "    positive_img = positive_img.resize((img_width,img_height))\n",
    "    positive_img_array = np.asarray(positive_img)\n",
    "    negative_img = Image.open(row[2])\n",
    "    negative_img = negative_img.resize((img_width,img_height))\n",
    "    negative_img_array = np.asarray(negative_img)\n",
    "    #x_train = np.array([anchor_img_array, positive_img_array, negative_img_array])\n",
    "    anchor  = np.array([anchor_img_array])\n",
    "    positive  = np.array([positive_img_array])\n",
    "    negative = np.array([negative_img_array])\n",
    "    model.fit(x = [anchor, positive, negative], y = np.ones(len(anchor)), epochs=1, callbacks=None, validation_steps=None)\n",
    "    #print(x_train.shape)\n",
    "    if index is 100:\n",
    "        break\n",
    "    inputlist.append([[anchor, positive, negative]])\n",
    "    outputlist.append(np.ones(len(anchor)))\n",
    "#print(inputlist.shape)\n",
    "datagen = [tuple((y, np.ones(len(y[0])))) for y in inputlist]\n",
    "#model.fit_generator(data_gen, steps_per_epoch=20, epochs=1, callbacks=None, validation_steps=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets begin with training. Iterate over triplets from dataframe and train the model on each run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
